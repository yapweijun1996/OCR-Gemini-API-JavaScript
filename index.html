<html>
	<head>
		<meta charset="utf-8" />
		<title>OCR with Google Gemini API</title>
		
		<!-- SEO Meta Tags -->
		<meta name="description" content="OCR with Google Gemini API performs image-based OCR using advanced models. Upload/paste your image to extract text effortlessly." />
		<meta name="keywords" content="OCR, Google Gemini API, Optical Character Recognition, image processing, OCR tool" />
		<meta name="author" content="yapweijun1996" />
		<meta name="robots" content="index, follow" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />

		<!-- Open Graph / Facebook -->
		<meta property="og:title" content="OCR with Google Gemini API" />
		<meta property="og:description" content="Extract text from images easily with our OCR tool powered by Google Gemini API." />
		<meta property="og:image" content="https://yapweijun1996.github.io/OCR-Gemini-API-JavaScript/og_img.jpg" />
		<meta property="og:url" content="https://yapweijun1996.github.io/OCR-Gemini-API-JavaScript/" />
		<meta property="og:type" content="website" />

		<!-- Twitter -->
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:title" content="OCR with Google Gemini API" />
		<meta name="twitter:description" content="Extract text from images easily with our OCR tool powered by Google Gemini API." />
		<meta name="twitter:image" content="https://yapweijun1996.github.io/OCR-Gemini-API-JavaScript/og_img.jpg" />

		<style>
			body {
				font-family: Arial, sans-serif;
				margin: 20px;
			}
			#container {
				max-width: 600px;
				margin: 0 auto;
			}
			#uploadSection {
				margin-bottom: 20px;
			}
			.message {
				padding: 8px;
				margin-bottom: 10px;
				border-radius: 4px;
				white-space: break-spaces;
			}
			.user {
				background: #f0f0f0;
			}
			.system {
				background: #fff3cd;
			}
			.model {
				background: #d4edda;
			}
			#chatMessages {
				border: 1px solid #ddd;
				padding: 10px;
				max-height: 95vh;
				min-height: 10vh;
				overflow-y: auto;
			}
			#downloadContainer a {
				display: block;
				margin-top: 5px;
			}
			select {
				margin-left: 10px;
			}
			/* Modal preview styles */
			#previewModal {
				position: fixed;
				top: 0;
				left: 0;
				width: 100%;
				height: 100%;
				background: rgba(0, 0, 0, 0.5);
				display: none;
				justify-content: center;
				align-items: center;
				z-index: 1000;
			}
			#previewModal.show {
				display: flex;
			}
			#previewModalContent {
				background: #fff;
				padding: 20px;
				border-radius: 8px;
				position: relative;
				max-width: 90%;
				max-height: 90%;
				overflow: auto;
			}
			#previewModalContent img {
				max-width: 100%;
				height: auto;
			}
			.closeBtn {
				position: absolute;
				top: 10px;
				right: 10px;
				background: #f00;
				color: #fff;
				border: none;
				font-size: 14px;
				padding: 3px 6px;
				cursor: pointer;
			}
			/* Style for thumbnail images inside chat */
			.chatImage {
				max-width: 200px;
				cursor: pointer;
				border: 1px solid #ccc;
				border-radius: 4px;
			}
		</style>
		<script src="./script.js"></script>
	</head>
	<body>
		<div id="container">
			<h1>OCR with Google Gemini API</h1>
			<div id="uploadSection">
				<input type="file" id="imageInput" accept="image/*" />
				<select id="modelSelect">
					<option value="gemini-2.0-flash">gemini-2.0-flash</option>
					<option value="gemma-3-27b-it">gemma-3-27b-it</option>
					<option value="gemini-2.5-pro-preview-03-25">gemini-2.5-pro-preview-03-25</option>
				</select>
				<button id="sendBtn">Perform OCR</button>
			</div>
			<div id="chatMessages"></div>
			<div id="downloadContainer"></div>
		</div>
		
		<!-- Modal Dialog for Image Preview -->
		<div id="previewModal">
			<div id="previewModalContent">
				<button class="closeBtn" onclick="closePreviewModal()">X</button>
				<img id="previewImage" src="" alt="Preview" />
			</div>
		</div>
		
		<script>
			// Simple configuration for Gemini API
			const generationConfig = {
				temperature: 1,
				topP: 0.95,
				topK: 40,
				maxOutputTokens: 8192,
				responseMimeType: "text/plain"
			};

			let chatHistory = [];

			// Append text messages to chatMessages container
			function appendMessage(role, text) {
				const chatMessages = document.getElementById("chatMessages");
				const msgDiv = document.createElement("div");
				msgDiv.className = "message " + role;
				msgDiv.textContent = text;
				chatMessages.appendChild(msgDiv);
				chatMessages.scrollTop = chatMessages.scrollHeight;
			}

			// Append an image message in chatMessages with a thumbnail
			function appendImageMessage(file) {
				const chatMessages = document.getElementById("chatMessages");
				const container = document.createElement("div");
				container.className = "message user";
				const img = document.createElement("img");
				img.className = "chatImage";
				img.src = URL.createObjectURL(file);
				img.alt = file.name || "pasted image";
				// On clicking the thumbnail, open modal preview
				img.onclick = function() {
					showPreview(file);
				};
				container.appendChild(img);
				chatMessages.appendChild(container);
				chatMessages.scrollTop = chatMessages.scrollHeight;
			}

			// Modal functions to display full image
			function showPreview(file) {
				const modal = document.getElementById("previewModal");
				const previewImage = document.getElementById("previewImage");
				previewImage.src = URL.createObjectURL(file);
				modal.classList.add("show");
			}

			function closePreviewModal() {
				const modal = document.getElementById("previewModal");
				modal.classList.remove("show");
				document.getElementById("previewImage").src = "";
			}

			// Convert file to Base64 string
			function readFileAsBase64(file) {
				return new Promise((resolve, reject) => {
					const reader = new FileReader();
					reader.onload = () => resolve(reader.result.split(",")[1]);
					reader.onerror = reject;
					reader.readAsDataURL(file);
				});
			}

			// Process inline data if returned from API (e.g., download links)
			function processInlineData(result) {
				const container = document.getElementById("downloadContainer");
				container.innerHTML = "";
				if (result.candidates) {
					result.candidates.forEach((cand, i) => {
						cand.content.parts.forEach((part, j) => {
							if (part.inline_data) {
								const bytes = atob(part.inline_data.data);
								let byteNumbers = [];
								for (let k = 0; k < bytes.length; k++) {
									byteNumbers.push(bytes.charCodeAt(k));
								}
								const blob = new Blob(
									[new Uint8Array(byteNumbers)],
									{ type: part.inline_data.mime_type }
								);
								const url = URL.createObjectURL(blob);
								const ext = part.inline_data.mime_type.split("/")[1] || "bin";
								const link = document.createElement("a");
								link.href = url;
								link.download = "output_" + i + "_" + j + "." + ext;
								link.textContent = "Download " + link.download;
								container.appendChild(link);
							}
						});
					});
				}
			}

			// Start chat session for the selected model
			async function startChatSession(selectedModel) {
				return {
					sendMessage: async function(messageData) {
						let userMessage = typeof messageData === "string"
							? { role: "user", parts: [{ text: messageData }] }
							: messageData;
						const requestBody = {
							contents: [...chatHistory, userMessage],
							generationConfig
						};
						const url = "https://generativelanguage.googleapis.com/v1beta/models/" + selectedModel +
							":generateContent?key=" + apiKey;
						const response = await fetch(url, {
							method: "POST",
							headers: { "Content-Type": "application/json" },
							body: JSON.stringify(requestBody)
						});
						if (!response.ok)
							throw new Error("API error " + response.status);
						const result = await response.json();
						if (result.candidates && result.candidates.length > 0) {
							const modelResponse = {
								role: "model",
								parts: result.candidates[0].content.parts
							};
							chatHistory.push(userMessage, modelResponse);
						} else {
							throw new Error("No response from API");
						}
						return result;
					}
				};
			}

			// Run OCR by sending the image and OCR instruction to the API
			async function runOCR() {
				const imageInput = document.getElementById("imageInput");
				const imageFile = imageInput.files[0];
				if (!imageFile) {
					alert("Please upload or paste an image.");
					return;
				}
				appendMessage("user", "Uploaded image: " + (imageFile.name || "pasted-image.png"));
				appendMessage("system", "Processing image for OCR...");

				let parts = [];
				try {
					const base64Data = await readFileAsBase64(imageFile);
					parts.push({
						text: "Extract text from the given image. The output text format must follow the same as the given image."
					});
					parts.push({
						inline_data: {
							data: base64Data,
							mime_type: imageFile.type
						}
					});
				} catch (err) {
					appendMessage("system", "Error reading image.");
					return;
				}
				const userMessage = { role: "user", parts };

				try {
					const modelSelect = document.getElementById("modelSelect");
					const selectedModel = modelSelect.value;
					const session = await startChatSession(selectedModel);
					const result = await session.sendMessage(userMessage);
					// Remove the "Processing..." message (last message)
					const chatMessages = document.getElementById("chatMessages");
					chatMessages.removeChild(chatMessages.lastChild);
					if (result.candidates && result.candidates.length > 0) {
						const candidate = result.candidates[0];
						const textResponse = candidate.content.parts
							.filter(p => p.text)
							.map(p => p.text)
							.join("\n");
						appendMessage("model", textResponse || "No text response.");
						processInlineData(result);
					}
				} catch (err) {
					appendMessage("system", "Error: " + err.message);
				}
			}

			// Event listener for file input change (manual selection)
			document.getElementById("imageInput").addEventListener("change", function(e) {
				const file = e.target.files[0];
				if (file) {
					appendImageMessage(file);
				}
			});

			// Handle paste event to support screenshot images from clipboard
			document.addEventListener("paste", function(e) {
				let items = e.clipboardData && e.clipboardData.items;
				if (!items) return;
				for (let i = 0; i < items.length; i++) {
					const item = items[i];
					if (item.kind === "file" && item.type.indexOf("image") !== -1) {
						const blob = item.getAsFile();
						// Set the file input to the pasted image using DataTransfer
						const dt = new DataTransfer();
						dt.items.add(blob);
						document.getElementById("imageInput").files = dt.files;
						appendImageMessage(blob);
						break; // Process only one image per paste
					}
				}
			});

			// Event listener for OCR button
			document.getElementById("sendBtn").addEventListener("click", runOCR);
		</script>
	</body>
</html>